#
# Copyright 2017 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: spark-streaming-checkpoint-s3
spec:
  type: Scala
  mode: cluster
  image: ghcr.io/netcracker/qubership-spark-sample-apps-spark-streaming-checkpoint:main
  imagePullPolicy: Always
  mainClass: com.qubership.spark.app.sample.JavaRecoverableKafkaWordCount
  mainApplicationFile: "local:///opt/spark/examples/spark-streaming-checkpoint-1.0-SNAPSHOT-jar-with-dependencies.jar"
  sparkVersion: "4.0.1"
  restartPolicy:
    type: Always
  #sparkConfigMap: log4j-properties
  sparkConf:
    "spark.jars.ivy": "/tmp/.ivy"
    "spark.checkpoint.directory": "s3a://spark/checkpoints"
    "spark.kafka.brokers": "kafka.kafka-service:9092"
    "spark.kafka.groupId": "spark-streaming-s3"
    "spark.kafka.topics": "spark-streaming-test-2"
    "spark.kafka.securityProtocol": "SASL_PLAINTEXT"
    "spark.kafka.saslMechanism": "SCRAM-SHA-512"
    "spark.kafka.saslJaasConfig": "org.apache.kafka.common.security.scram.ScramLoginModule required username=\"client\" password=\"client\";"
    #"spark.kubernetes.local.dirs.tmpfs": "true"
    "spark.kubernetes.submission.connectionTimeout": "60000000"
    "spark.kubernetes.submission.requestTimeout": "60000000"
    "spark.kubernetes.driver.connectionTimeout": "60000000"
    "spark.kubernetes.driver.requestTimeout": "60000000"
  hadoopConf:
    "fs.s3a.endpoint": http://minio-endpoint.cloud.qubership.com
    #"fs.s3a.access.key": minioaccesskey
    #"fs.s3a.secret.key": miniosecretkey
    "fs.s3a.impl": org.apache.hadoop.fs.s3a.S3AFileSystem
    "fs.s3a.connection.ssl.enabled": "false"
    "fs.s3a.path.style.access": "true"
    "fs.s3a.committer.magic.enabled": "false"
    "fs.s3a.committer.name": directory
    "fs.s3a.committer.staging.abort.pending.uploads": "true"
    "fs.s3a.committer.staging.conflict-mode": append
    "fs.s3a.connection.timeout": "200000"
  driver:
    cores: 1
    coreLimit: "1200m"
    memory: "512m"
    labels:
      version: 4.0.1
    serviceAccount: sparkapps-sa
    securityContext:
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 185
      capabilities:
        drop:
          - ALL
    env:
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: s3-cred
            key: accesskey
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: s3-cred
            key: secretkey
  executor:
    cores: 1
    instances: 1
    memory: "512m"
    labels:
      version: 4.0.1
    securityContext:
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 185
      capabilities:
        drop:
          - ALL
    env:
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: s3-cred
            key: accesskey
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: s3-cred
            key: secretkey