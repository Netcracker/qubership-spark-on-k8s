#
# Copyright 2017 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: spark-streaming-kafka-word-count
spec:
  type: Scala
  mode: cluster
  image: "ghcr.io/netcracker/qubership-spark-sample-apps-spark-streaming-word-count:main"
  imagePullPolicy: Always
  mainClass: com.qubership.spark.app.sample.JavaDirectKafkaWordCount
  mainApplicationFile: "local:///opt/spark/examples/spark-streaming-1.0-SNAPSHOT-jar-with-dependencies.jar"
  sparkVersion: "4.0.1"
  restartPolicy:
    type: Never
  sparkConf:
    "spark.jars.ivy": "/tmp/.ivy"
    spark.kafka.brokers: "kafka.kafka-service:9092"
    spark.kafka.groupId: "spark-streaming-word-count"
    spark.kafka.topics: "spark-streaming-test"
    spark.kafka.securityProtocol: "SASL_PLAINTEXT"
    spark.kafka.saslMechanism: "SCRAM-SHA-512"
    spark.kafka.saslJaasConfig: "org.apache.kafka.common.security.scram.ScramLoginModule required username=\"client\" password=\"client\";"
    spark.ui.prometheus.enabled: "true"
    spark.executor.processTreeMetrics.enabled: "true"
    spark.metrics.conf: "/etc/metrics/conf/metrics.properties"
    #"spark.kubernetes.local.dirs.tmpfs": "true"
    "spark.kubernetes.submission.connectionTimeout": "60000000"
    "spark.kubernetes.submission.requestTimeout": "60000000"
    "spark.kubernetes.driver.connectionTimeout": "60000000"
    "spark.kubernetes.driver.requestTimeout": "60000000"
  driver:
    configMaps:
      - name: testconfigmap2
        path: /etc/metrics/conf
    cores: 1
    coreLimit: "1200m"
    memory: "512m"
    labels:
      version: 4.0.1
    serviceAccount: sparkapps-sa
    securityContext:
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 185
      capabilities:
        drop:
          - ALL
  executor:
    configMaps:
      - name: testconfigmap2
        path: /etc/metrics/conf
    cores: 1
    instances: 1
    memory: "512m"
    labels:
      version: 4.0.1
    securityContext:
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 185
      capabilities:
        drop:
          - ALL