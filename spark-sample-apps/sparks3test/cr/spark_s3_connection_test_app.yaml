apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: s3-json-read-test
  namespace: spark-apps
spec:
  type: Python
  pythonVersion: "3"
  mode: cluster
  image: ghcr.io/netcracker/qubership-tests-spark-s3-connection:main
  imagePullPolicy: Always
  mainApplicationFile: local:///opt/spark/examples/s3_read_test.py
  sparkVersion: "4.0.0"
  restartPolicy:
    type: Never
  volumes:
    - name: s3-certs
      secret:
        secretName: s3certificates
  driver:
    cores: 1
    memory: 1g
    env:
      - name: TRUST_CERTS_DIR
        value: /opt/spark/cacerts
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: s3-credentials
            key: AWS_ACCESS_KEY_ID
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: s3-credentials
            key: AWS_SECRET_ACCESS_KEY
      - name: S3_JSON_FILE
        value: s3a://sparktest/test.JSON            
    volumeMounts:
      - name: s3-certs
        mountPath: /opt/spark/cacerts
        readOnly: true      
    labels:
      version: 4.0.0
    serviceAccount: sparkapps-sa
    securityContext:
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 185
      capabilities:
        drop:
          - ALL

  executor:
    cores: 1
    instances: 1
    memory: 1g
    env:
      - name: TRUST_CERTS_DIR
        value: /opt/spark/cacerts  
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: s3-credentials
            key: AWS_ACCESS_KEY_ID
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: s3-credentials
            key: AWS_SECRET_ACCESS_KEY
      - name: S3_JSON_FILE
        value: s3a://sparktest/test.JSON            
    volumeMounts:
      - name: s3-certs
        mountPath: /opt/spark/cacerts
        readOnly: true             
    labels:
      version: 4.0.0
    securityContext:
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 185
      capabilities:
        drop:
          - ALL 
  deps:
    pyFiles:
      - s3a://sparktest/test.JSON
  sparkConf:
    spark.hadoop.fs.s3a.endpoint: "https://minio-s3.com"
    spark.hadoop.fs.s3a.path.style.access: "true"
    spark.driver.extraJavaOptions: "-Djavax.net.ssl.trustStore=/opt/spark/cacerts -Djavax.net.ssl.trustStorePassword=changeit"
    spark.executor.extraJavaOptions: "-Djavax.net.ssl.trustStore=/opt/spark/cacerts -Djavax.net.ssl.trustStorePassword=changeit"
