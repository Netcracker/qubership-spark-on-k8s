apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: s3-json-read-test-3
  namespace: spark-apps
spec:
  type: Python
  pythonVersion: "3"
  mode: cluster
  image: ghcr.io/netcracker/qubership-tests-spark-hive-connection:mai
  imagePullPolicy: Always
  mainApplicationFile: local:///opt/spark/examples/s3_read_test.py
  sparkVersion: "4.0.0"
  restartPolicy:
    type: Never
  volumes:
      - name: s3certificates-volume
        secret:
          secretName: s3certificates
      - name: writable-volume
        emptyDir: {}  
  driver:
    cores: 1
    memory: 1g
    env:
      - name: S3_CERTS_DIR
        value: /opt/spark/s3certificates
      - name: JAVA_WRITABLE_KEYSTORE
        value: /opt/spark/writable/cacerts      
    labels:
      version: 4.0.0
    serviceAccount: sparkapps-sa
    securityContext:
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 185
      capabilities:
        drop:
          - ALL
    volumeMounts:
      - name: s3certificates-volume
        mountPath: /opt/spark/s3certificates
        readOnly: true
      - name: writable-volume
        mountPath: /opt/spark/writable 

  executor:
    cores: 1
    instances: 1
    memory: 1g
    env:
      - name: S3_CERTS_DIR
        value: /opt/spark/s3certificates
      - name: JAVA_WRITABLE_KEYSTORE
        value: /opt/spark/writable/cacerts
             
    labels:
      version: 4.0.0
    securityContext:
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 185
      capabilities:
        drop:
          - ALL
    volumeMounts:
      - name: s3certificates-volume
        mountPath: /opt/spark/s3certificates
        readOnly: true
      - name: writable-volume
        mountPath: /opt/spark/writable 
      
  env:
    - name: S3_CERTS_DIR
      value: /opt/spark/s3certificates
    - name: JAVA_WRITABLE_KEYSTORE
      value: /opt/spark/writable/cacerts
  deps:
    pyFiles:
      - s3a://sparktest/test.JSON
  sparkConf:
    spark.local.dir: /tmp
    java.io.tmpdir: /tmp
    spark.hadoop.fs.s3a.access.key: "accesskey"
    spark.hadoop.fs.s3a.secret.key: "secretkey"
    spark.hadoop.fs.s3a.endpoint: "https://minio.com"
    spark.hadoop.fs.s3a.path.style.access: "true"
    spark.driver.extraJavaOptions: "-Djavax.net.ssl.trustStore=/opt/spark/writable/cacerts -Djavax.net.ssl.trustStorePassword=changeit -Djava.io.tmpdir=/opt/spark/tmp"
    spark.executor.extraJavaOptions: "-Djavax.net.ssl.trustStore=/opt/spark/writable/cacerts -Djavax.net.ssl.trustStorePassword=changeit -Djava.io.tmpdir=/opt/spark/tmp"
