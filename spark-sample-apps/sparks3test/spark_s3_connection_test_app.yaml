apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: s3-connection-test
  namespace: spark-apps
spec:
  type: Python
  pythonVersion: "3"
  mode: cluster
  image: ghcr.io/netcracker/qubership-spark-customized-py:main
  imagePullPolicy: Always
  mainApplicationFile: local:////opt/spark/work-dir/sparkapp/app/json_read.py
  sparkVersion: "4.0.0"
  restartPolicy:
    type: Never
  volumes:
    - name: s3-certs-volume
      secret:
        secretName: s3-certificates
    - name: s3-connection-config-volume
      secret:
        secretName: s3-connection-config
        defaultMode: 444    
  driver:
    cores: 1
    memory: 1g
    env:
      - name: TRUST_CERTS_DIR
        value: /opt/spark/cacerts
      - name: S3_JSON_FILE
        value: /opt/spark/work-dir/test.json
      - name: HADOOP_CONF_DIR
        value: /opt/spark/s3config
      - name: SPARK_CONF_DIR
        value: /opt/spark/s3config         
    volumeMounts:
      - name: s3-certs-volume
        mountPath: /opt/spark/cacerts
        readOnly: true
      - name: s3-connection-config-volume
        mountPath: /opt/spark/s3config
        readOnly: true        
    labels:
      version: 4.0.0
    serviceAccount: sparkapps-sa
    securityContext:
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 185
      capabilities:
        drop:
          - ALL

  executor:
    cores: 1
    instances: 1
    memory: 1g
    env:
      - name: TRUST_CERTS_DIR
        value: /opt/spark/cacerts  
      - name: S3_JSON_FILE
        value: /opt/spark/work-dir/test.json
      - name: HADOOP_CONF_DIR
        value: /opt/spark/s3config
      - name: SPARK_CONF_DIR
        value: /opt/spark/s3config        
    volumeMounts:
      - name: s3-certs-volume
        mountPath: /opt/spark/cacerts
        readOnly: true
      - name: s3-connection-config-volume
        mountPath: /opt/spark/s3config
        readOnly: true          
    labels:
      version: 4.0.0
    securityContext:
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsUser: 185
      capabilities:
        drop:
          - ALL 
  deps:
    pyFiles:
      - s3a://{S3 BUCKET}/test.JSON
  sparkConf:
    spark.hadoop.fs.s3a.path.style.access: "true"
    spark.archives: s3a://{S3 BUCKET}/app.zip#sparkapp
    spark.driver.extraJavaOptions: "-Djavax.net.ssl.trustStore=/opt/spark/cacerts -Djavax.net.ssl.trustStorePassword=changeit"
    spark.executor.extraJavaOptions: "-Djavax.net.ssl.trustStore=/opt/spark/cacerts -Djavax.net.ssl.trustStorePassword=changeit"
